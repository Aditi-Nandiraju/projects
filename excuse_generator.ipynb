{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFOHtDwtH6__"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "vdfMeOKiWJ-9",
        "outputId": "040c66f2-79c5-4fe5-cdea-8a909634eead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FLAN-T5 Excuse + Fake Proof Generator & CSV Saver ===\n",
            "Loaded 0 existing excuses from excuse_history.csv\n",
            "Enter a situation (e.g., I missed the test): missed project deadline \n",
            "What tone should the apology have? (casual, formal, emotional - default emotional): emotional\n",
            "\n",
            "üìù Generated 5 Excuses:\n",
            "1.  I'm trying to be smarter.\n",
            "2.  I was working late because I had a meeting with a client\n",
            "3.  i'm lazy , i forgot to pay bills and that is the reason i'm late\n",
            "4.  It was too many things to complete\n",
            "5.  I had to travel for work and I got stuck at home\n",
            "\n",
            "üèÖ Ranked Excuses (Current Run):\n",
            "1. Effectiveness: 0.98 -  It was too many things to complete\n",
            "2. Effectiveness: 0.97 -  i'm lazy , i forgot to pay bills and that is the reason i'm late\n",
            "3. Effectiveness: 0.96 -  I had to travel for work and I got stuck at home\n",
            "4. Effectiveness: 0.93 -  I was working late because I had a meeting with a client\n",
            "5. Effectiveness: 0.62 -  I'm trying to be smarter.\n",
            "\n",
            "Select an excuse number (1-5) from the GENERATED list above to generate proofs for, or enter 0 to skip proofs: 1\n",
            "\n",
            "Generating proofs for selected excuse:  I'm trying to be smarter.\n",
            "Do you want a fake chat log for this excuse? (yes/no): no\n",
            "Do you want a fake medical note? (yes/no): no\n",
            "Do you want a fake location log? (yes/no): no\n",
            "\n",
            "Excuse data saved to excuse_history.csv\n",
            "\n",
            "=== Full Excuse History from CSV ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3436656448.py:285: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  all_excuses_df = pd.concat([all_excuses_df, new_excuses_df], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    Context       Tone                      Excuse  Apology  \\\n",
              "0  missed project deadline   emotional   I'm trying to be smarter.      NaN   \n",
              "\n",
              "  Proofs  Calls  Effectiveness  \n",
              "0     {}      0       0.618033  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6dfb5620-2393-41c6-adb2-ef580811f279\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context</th>\n",
              "      <th>Tone</th>\n",
              "      <th>Excuse</th>\n",
              "      <th>Apology</th>\n",
              "      <th>Proofs</th>\n",
              "      <th>Calls</th>\n",
              "      <th>Effectiveness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>missed project deadline</td>\n",
              "      <td>emotional</td>\n",
              "      <td>I'm trying to be smarter.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{}</td>\n",
              "      <td>0</td>\n",
              "      <td>0.618033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6dfb5620-2393-41c6-adb2-ef580811f279')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6dfb5620-2393-41c6-adb2-ef580811f279 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6dfb5620-2393-41c6-adb2-ef580811f279');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(load_excuses_from_csv())\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"missed project deadline \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tone\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"emotional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Excuse\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \" I'm trying to be smarter.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Apology\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Proofs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Effectiveness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6180327437727257,\n        \"max\": 0.6180327437727257,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, date # Import date explicitly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline # Import pipeline here\n",
        "import torch\n",
        "\n",
        "# === Constants ===\n",
        "\n",
        "CSV_FILE = 'excuse_history.csv'\n",
        "DISCLAIMER = \"Disclaimer: This chat log is fictional and generated by an AI. It should not be used for deceptive purposes.\"\n",
        "\n",
        "# === Excuse Data Structure ===\n",
        "class ExcuseData:\n",
        "    def __init__(self, context, tone, excuse, apology, proofs=None, calls=0, effectiveness=None):\n",
        "        self.context = context\n",
        "        self.tone = tone\n",
        "        self.excuse = excuse\n",
        "        self.apology = apology\n",
        "        self.proofs = proofs if proofs is not None else {}\n",
        "        self.calls = calls\n",
        "        self.effectiveness = effectiveness\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"Context\": self.context,\n",
        "            \"Tone\": self.tone,\n",
        "            \"Excuse\": self.excuse,\n",
        "            \"Apology\": self.apology,\n",
        "            \"Proofs\": json.dumps(self.proofs), # Convert proofs dictionary to JSON string\n",
        "            \"Calls\": self.calls,\n",
        "            \"Effectiveness\": self.effectiveness\n",
        "        }\n",
        "\n",
        "# === Load FLAN-T5 Model ===\n",
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# === FLAN-T5 Excuse Generator ===\n",
        "def generate_excuses(situation, num_excuses=5, max_length=50):\n",
        "    prompt = f\"Give {num_excuses} creative excuses for the following situation: {situation}\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=num_excuses,\n",
        "            temperature=0.9,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    excuses = []\n",
        "    for output in outputs:\n",
        "        decoded = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        # Prefix disclaimer\n",
        "        excuses.append(f\" {decoded}\")\n",
        "    return excuses\n",
        "\n",
        "# Excuse History & Ranking (using the ExcuseData structure)\n",
        "excuse_history_data = [] # Use this list to store ExcuseData objects for the current run\n",
        "\n",
        "def add_excuse_data(excuse_data):\n",
        "    excuse_history_data.append(excuse_data)\n",
        "\n",
        "def rank_excuses_data(excuse_list): # Modified to accept a list\n",
        "    # Rank based on the effectiveness stored in ExcuseData objects\n",
        "    return sorted(excuse_list, key=lambda x: x.effectiveness if x.effectiveness is not None else -1, reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "# === Fictional Chat Generator ===\n",
        "def generate_fake_chat(excuse):\n",
        "    # Return the chat log data instead of printing\n",
        "    return [\n",
        "        {\"sender\": \"Mom\", \"time\": \"8:42 AM\", \"message\": \"Where are you?? Your professor called üò°\"},\n",
        "        {\"sender\": \"You\", \"time\": \"8:43 AM\", \"message\": excuse},\n",
        "        {\"sender\": \"Mom\", \"time\": \"8:43 AM\", \"message\": \"Send a picture right now.\"},\n",
        "        {\"sender\": \"You\", \"time\": \"8:44 AM\", \"message\": \"Sent you one just now, look at the jam. I‚Äôll be there ASAP.\"},\n",
        "        {\"sender\": \"System\", \"time\": \"Generated Now\", \"message\": DISCLAIMER}\n",
        "    ]\n",
        "\n",
        "\n",
        "# === Medical Certificate Generator ===\n",
        "def generate_fake_medical_note(patient_name=\"John Doe\", reason=\"\"):\n",
        "    today = date.today() # Use date.today()\n",
        "    issue_date = today.strftime(\"%B %d, %Y\")\n",
        "    rest_days = random.randint(2, 7)\n",
        "\n",
        "    certificate_text = f\"\"\"\n",
        "------------------------------------------------------------\n",
        "                         MEDICAL CERTIFICATE\n",
        "------------------------------------------------------------\n",
        "\n",
        "To Whom It May Concern,\n",
        "\n",
        "This is to certify that {patient_name} has been under my care and treatment\n",
        "for the following medical reason: {reason}. The patient reported symptoms\n",
        "requiring clinical attention and was advised to take adequate rest.\n",
        "\n",
        "It is hereby recommended that {patient_name} be granted leave for a period\n",
        "of {rest_days} days, starting from {issue_date}, in order to facilitate recovery.\n",
        "\n",
        "Should you have any questions, you may contact my clinic directly.\n",
        "\n",
        "Sincerely,\n",
        "\n",
        "\n",
        "M.B.B.S., M.D.\n",
        "Reg. No: {random.randint(100000, 999999)}\n",
        "Clinic: Health First Multispeciality, Hyderabad\n",
        "Date Issued: {issue_date}\n",
        "------------------------------------------------------------\n",
        "\"\"\"\n",
        "    return certificate_text\n",
        "\n",
        "# === Fake Location Log ===\n",
        "def generate_fake_location_log():\n",
        "    # Return the location log data instead of printing\n",
        "    now = datetime.now()\n",
        "    locations = [\n",
        "        {\n",
        "            \"timestamp\": now.isoformat(),\n",
        "            \"latitude\": 12.9716,\n",
        "            \"longitude\": 77.5946,\n",
        "\n",
        "        },\n",
        "        {\n",
        "            \"timestamp\": (now + timedelta(minutes=90)).isoformat(),\n",
        "            \"latitude\": 12.9353,\n",
        "            \"longitude\": 77.6143,\n",
        "\n",
        "        }\n",
        "    ]\n",
        "    return {\n",
        "\n",
        "        \"location_log\": locations\n",
        "    }\n",
        "\n",
        "# === Guilt-Tripping Apology Generator (using pipeline from previous cells) ===\n",
        "apology_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "def generate_apology(context, tone=\"emotional\"):\n",
        "    prompt = f\"I'm deeply sorry for {context}. I feel really {tone} about it because\"\n",
        "    # Ensure prompt is within a reasonable length for the model\n",
        "    if len(prompt) > tokenizer.model_max_length:\n",
        "        prompt = prompt[:tokenizer.model_max_length]\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    # Check if pad_token_id is None and set it to eos_token_id if it is\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    # Create attention mask\n",
        "    attention_mask = inputs['input_ids'].ne(tokenizer.pad_token_id)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        apology_outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=50, # Limit apology length\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            # attention_mask=attention_mask # Removed redundant attention mask\n",
        "        )\n",
        "    apology = tokenizer.decode(apology_outputs[0], skip_special_tokens=True)\n",
        "    # Remove the prompt from the generated text\n",
        "    apology = apology[len(prompt):].strip()\n",
        "    return apology\n",
        "\n",
        "\n",
        "# === CSV Handling Functions ===\n",
        "def load_excuses_from_csv(filepath=CSV_FILE):\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        # Convert the 'Proofs' column from JSON string back to dictionary\n",
        "        if 'Proofs' in df.columns:\n",
        "            df['Proofs'] = df['Proofs'].apply(lambda x: json.loads(x) if pd.notnull(x) else {})\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        return pd.DataFrame(columns=[\"Context\", \"Tone\", \"Excuse\", \"Apology\", \"Proofs\", \"Calls\", \"Effectiveness\"])\n",
        "\n",
        "def save_excuses_to_csv(df, filepath=CSV_FILE):\n",
        "    # Convert the 'Proofs' column (dictionaries) to JSON strings before saving\n",
        "    if 'Proofs' in df.columns:\n",
        "        df['Proofs'] = df['Proofs'].apply(lambda x: json.dumps(x) if isinstance(x, dict) else x)\n",
        "    df.to_csv(filepath, index=False)\n",
        "    print(f\"\\nExcuse data saved to {filepath}\")\n",
        "\n",
        "# === Main Program ===\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== FLAN-T5 Excuse + Fake Proof Generator & CSV Saver ===\")\n",
        "\n",
        "    # Load existing data from CSV\n",
        "    all_excuses_df = load_excuses_from_csv()\n",
        "    print(f\"Loaded {len(all_excuses_df)} existing excuses from {CSV_FILE}\")\n",
        "\n",
        "    # Get user inputs for scenario and tone\n",
        "    scenario = input(\"Enter a situation (e.g., I missed the test): \")\n",
        "    # Add input for tone, as used in apology generation\n",
        "    tone = input(\"What tone should the apology have? (casual, formal, emotional - default emotional): \") or \"emotional\"\n",
        "\n",
        "\n",
        "    # Generate excuses with FLAN-T5\n",
        "    generated_excuses_text = generate_excuses(scenario, num_excuses=5)\n",
        "\n",
        "    print(f\"\\nüìù Generated {len(generated_excuses_text)} Excuses:\")\n",
        "    current_run_excuses = [] # List to hold ExcuseData objects for the current run\n",
        "\n",
        "    for i, excuse_text in enumerate(generated_excuses_text):\n",
        "        # Generate apology for each excuse (using the scenario as context)\n",
        "        apology_text = generate_apology(scenario, tone)\n",
        "\n",
        "        # Create an ExcuseData object for each generated excuse\n",
        "        excuse_data = ExcuseData(\n",
        "            context=scenario,\n",
        "            tone=tone,\n",
        "            excuse=excuse_text,\n",
        "            apology=apology_text,\n",
        "            effectiveness=random.uniform(0.5, 1.0) # Assign random effectiveness for now\n",
        "        )\n",
        "        current_run_excuses.append(excuse_data)\n",
        "        print(f\"{i+1}. {excuse_text}\")\n",
        "\n",
        "    # Rank the excuses from the current run\n",
        "    ranked_current_excuses = rank_excuses_data(current_run_excuses) # Pass the list to rank_excuses_data\n",
        "    print(\"\\nüèÖ Ranked Excuses (Current Run):\")\n",
        "    for i, excuse_data in enumerate(ranked_current_excuses):\n",
        "         print(f\"{i+1}. Effectiveness: {excuse_data.effectiveness:.2f} - {excuse_data.excuse}\")\n",
        "\n",
        "    # Ask user to select an excuse for proofs\n",
        "    selected_excuse_data = None\n",
        "    while True:\n",
        "        try:\n",
        "            selection = int(input(f\"\\nSelect an excuse number (1-{len(current_run_excuses)}) from the GENERATED list above to generate proofs for, or enter 0 to skip proofs: \"))\n",
        "            if 0 <= selection <= len(current_run_excuses):\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid selection. Please enter a number within the range.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    new_excuses_to_save_dicts = [] # List to hold dictionaries of selected excuse for saving\n",
        "    if selection > 0:\n",
        "        selected_excuse_data = current_run_excuses[selection - 1]\n",
        "        # print(f\"Type of selected_excuse_data: {type(selected_excuse_data)}\") # Added for debugging\n",
        "        print(f\"\\nGenerating proofs for selected excuse: {selected_excuse_data.excuse}\")\n",
        "\n",
        "        proofs = {}\n",
        "        # Chat log\n",
        "        if input(\"Do you want a fake chat log for this excuse? (yes/no): \").strip().lower() == 'yes':\n",
        "            chat_log_data = generate_fake_chat(selected_excuse_data.excuse)\n",
        "            proofs['chat_log'] = chat_log_data # Store the data\n",
        "            print(\"\\nüì± Chat Log:\")\n",
        "            for msg in chat_log_data:\n",
        "                print(f\"[{msg['sender']} - {msg['time']}] {msg['message']}\")\n",
        "\n",
        "        # Medical note\n",
        "        if input(\"Do you want a fake medical note? (yes/no): \").strip().lower() == 'yes':\n",
        "            medical_note_text = generate_fake_medical_note()\n",
        "            proofs['medical_note'] = medical_note_text # Store the text\n",
        "            print(\"\\nüìÑ Medical Note:\")\n",
        "            print(medical_note_text)\n",
        "\n",
        "        # Location log\n",
        "        if input(\"Do you want a fake location log? (yes/no): \").strip().lower() == 'yes':\n",
        "            location_log_data = generate_fake_location_log()\n",
        "            proofs['location_log'] = location_log_data # Store the data\n",
        "            print(\"\\nüìç Location Log (JSON):\")\n",
        "            print(json.dumps(location_log_data, indent=4))\n",
        "\n",
        "        # Update the selected ExcuseData object with generated proofs\n",
        "        selected_excuse_data.proofs = proofs\n",
        "        new_excuses_to_save_dicts.append(selected_excuse_data.to_dict()) # Add selected excuse to the list for saving\n",
        "\n",
        "    else:\n",
        "        print(\"\\nSkipping proof generation and saving for this run.\")\n",
        "\n",
        "    # Convert the selected excuse data to a DataFrame (will be empty if no excuse was selected)\n",
        "    new_excuses_df = pd.DataFrame(new_excuses_to_save_dicts)\n",
        "\n",
        "    # Append new data to the existing DataFrame\n",
        "    all_excuses_df = pd.concat([all_excuses_df, new_excuses_df], ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame back to CSV\n",
        "    save_excuses_to_csv(all_excuses_df)\n",
        "\n",
        "    # Optional: Display the full history from the CSV\n",
        "    print(\"\\n=== Full Excuse History from CSV ===\")\n",
        "    display(load_excuses_from_csv())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--C8Ql4OKu9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "679ca60d-4ed9-447b-fee9-7ff1db7616f1",
        "id": "1d8NmA_XKvO_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FLAN-T5 Excuse + Fake Proof Generator & CSV Saver ===\n",
            "Loaded 1 existing excuses from excuse_history.csv\n",
            "Enter a situation (e.g., I missed the test): I didn't come for an exam \n",
            "What tone should the apology have? (casual, formal, emotional - default emotional): formal\n",
            "\n",
            "üìù Generated 5 Excuses:\n",
            "1.  I just kept having to stay home.\n",
            "2.  I got a full day off before the exam.\n",
            "3.  I missed it\n",
            "4.  I didn't want to go\n",
            "5.  I was out of town.\n",
            "\n",
            "üèÖ Ranked Excuses (Current Run):\n",
            "1. Effectiveness: 0.97 -  I just kept having to stay home.\n",
            "2. Effectiveness: 0.91 -  I missed it\n",
            "3. Effectiveness: 0.73 -  I got a full day off before the exam.\n",
            "4. Effectiveness: 0.56 -  I was out of town.\n",
            "5. Effectiveness: 0.53 -  I didn't want to go\n",
            "\n",
            "Select an excuse number (1-5) from the GENERATED list above to generate proofs for, or enter 0 to skip proofs: 5\n",
            "\n",
            "Generating proofs for selected excuse:  I was out of town.\n",
            "Do you want a fake chat log for this excuse? (yes/no): no\n",
            "Do you want a fake medical note? (yes/no): no\n",
            "Do you want a fake location log? (yes/no): yes\n",
            "\n",
            "üìç Location Log (JSON):\n",
            "{\n",
            "    \"location_log\": [\n",
            "        {\n",
            "            \"timestamp\": \"2025-08-10T08:49:38.815455\",\n",
            "            \"latitude\": 12.9716,\n",
            "            \"longitude\": 77.5946\n",
            "        },\n",
            "        {\n",
            "            \"timestamp\": \"2025-08-10T10:19:38.815455\",\n",
            "            \"latitude\": 12.9353,\n",
            "            \"longitude\": 77.6143\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "Excuse data saved to excuse_history.csv\n",
            "\n",
            "=== Full Excuse History from CSV ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      Context       Tone                      Excuse  Apology  \\\n",
              "0    missed project deadline   emotional   I'm trying to be smarter.      NaN   \n",
              "1  I didn't come for an exam      formal          I was out of town.      NaN   \n",
              "\n",
              "                                              Proofs  Calls  Effectiveness  \n",
              "0                                                 {}      0       0.618033  \n",
              "1  {'location_log': {'location_log': [{'timestamp...      0       0.560939  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a28034d-8099-4c97-a9bf-059c4d4be56d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context</th>\n",
              "      <th>Tone</th>\n",
              "      <th>Excuse</th>\n",
              "      <th>Apology</th>\n",
              "      <th>Proofs</th>\n",
              "      <th>Calls</th>\n",
              "      <th>Effectiveness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>missed project deadline</td>\n",
              "      <td>emotional</td>\n",
              "      <td>I'm trying to be smarter.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{}</td>\n",
              "      <td>0</td>\n",
              "      <td>0.618033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I didn't come for an exam</td>\n",
              "      <td>formal</td>\n",
              "      <td>I was out of town.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'location_log': {'location_log': [{'timestamp...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a28034d-8099-4c97-a9bf-059c4d4be56d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a28034d-8099-4c97-a9bf-059c4d4be56d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a28034d-8099-4c97-a9bf-059c4d4be56d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ce8e7fef-a305-4ee9-8ba0-482fd25e0315\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce8e7fef-a305-4ee9-8ba0-482fd25e0315')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ce8e7fef-a305-4ee9-8ba0-482fd25e0315 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(load_excuses_from_csv())\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"I didn't come for an exam \",\n          \"missed project deadline \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tone\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"formal\",\n          \"emotional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Excuse\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" I was out of town.\",\n          \" I'm trying to be smarter.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Apology\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Proofs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Effectiveness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040371294838960896,\n        \"min\": 0.5609391110809042,\n        \"max\": 0.6180327437727257,\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, date # Import date explicitly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline # Import pipeline here\n",
        "import torch\n",
        "\n",
        "# === Constants ===\n",
        "\n",
        "CSV_FILE = 'excuse_history.csv'\n",
        "DISCLAIMER = \"Disclaimer: This chat log is fictional and generated by an AI. It should not be used for deceptive purposes.\"\n",
        "\n",
        "# === Excuse Data Structure ===\n",
        "class ExcuseData:\n",
        "    def __init__(self, context, tone, excuse, apology, proofs=None, calls=0, effectiveness=None):\n",
        "        self.context = context\n",
        "        self.tone = tone\n",
        "        self.excuse = excuse\n",
        "        self.apology = apology\n",
        "        self.proofs = proofs if proofs is not None else {}\n",
        "        self.calls = calls\n",
        "        self.effectiveness = effectiveness\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"Context\": self.context,\n",
        "            \"Tone\": self.tone,\n",
        "            \"Excuse\": self.excuse,\n",
        "            \"Apology\": self.apology,\n",
        "            \"Proofs\": json.dumps(self.proofs), # Convert proofs dictionary to JSON string\n",
        "            \"Calls\": self.calls,\n",
        "            \"Effectiveness\": self.effectiveness\n",
        "        }\n",
        "\n",
        "# === Load FLAN-T5 Model ===\n",
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# === FLAN-T5 Excuse Generator ===\n",
        "def generate_excuses(situation, num_excuses=5, max_length=50):\n",
        "    prompt = f\"Give {num_excuses} creative excuses for the following situation: {situation}\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=num_excuses,\n",
        "            temperature=0.9,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    excuses = []\n",
        "    for output in outputs:\n",
        "        decoded = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        # Prefix disclaimer\n",
        "        excuses.append(f\" {decoded}\")\n",
        "    return excuses\n",
        "\n",
        "# Excuse History & Ranking (using the ExcuseData structure)\n",
        "excuse_history_data = [] # Use this list to store ExcuseData objects for the current run\n",
        "\n",
        "def add_excuse_data(excuse_data):\n",
        "    excuse_history_data.append(excuse_data)\n",
        "\n",
        "def rank_excuses_data(excuse_list): # Modified to accept a list\n",
        "    # Rank based on the effectiveness stored in ExcuseData objects\n",
        "    return sorted(excuse_list, key=lambda x: x.effectiveness if x.effectiveness is not None else -1, reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "# === Fictional Chat Generator ===\n",
        "def generate_fake_chat(excuse):\n",
        "    # Return the chat log data instead of printing\n",
        "    return [\n",
        "        {\"sender\": \"Mom\", \"time\": \"8:42 AM\", \"message\": \"Where are you?? Your professor called üò°\"},\n",
        "        {\"sender\": \"You\", \"time\": \"8:43 AM\", \"message\": excuse},\n",
        "        {\"sender\": \"Mom\", \"time\": \"8:43 AM\", \"message\": \"Send a picture right now.\"},\n",
        "        {\"sender\": \"You\", \"time\": \"8:44 AM\", \"message\": \"Sent you one just now, look at the jam. I‚Äôll be there ASAP.\"},\n",
        "        {\"sender\": \"System\", \"time\": \"Generated Now\", \"message\": DISCLAIMER}\n",
        "    ]\n",
        "\n",
        "\n",
        "# === Medical Certificate Generator ===\n",
        "def generate_fake_medical_note(patient_name=\"John Doe\", reason=\"\"):\n",
        "    today = date.today() # Use date.today()\n",
        "    issue_date = today.strftime(\"%B %d, %Y\")\n",
        "    rest_days = random.randint(2, 7)\n",
        "\n",
        "    certificate_text = f\"\"\"\n",
        "------------------------------------------------------------\n",
        "                         MEDICAL CERTIFICATE\n",
        "------------------------------------------------------------\n",
        "\n",
        "To Whom It May Concern,\n",
        "\n",
        "This is to certify that {patient_name} has been under my care and treatment\n",
        "for the following medical reason: {reason}. The patient reported symptoms\n",
        "requiring clinical attention and was advised to take adequate rest.\n",
        "\n",
        "It is hereby recommended that {patient_name} be granted leave for a period\n",
        "of {rest_days} days, starting from {issue_date}, in order to facilitate recovery.\n",
        "\n",
        "Should you have any questions, you may contact my clinic directly.\n",
        "\n",
        "Sincerely,\n",
        "\n",
        "\n",
        "M.B.B.S., M.D.\n",
        "Reg. No: {random.randint(100000, 999999)}\n",
        "Clinic: Health First Multispeciality, Hyderabad\n",
        "Date Issued: {issue_date}\n",
        "------------------------------------------------------------\n",
        "\"\"\"\n",
        "    return certificate_text\n",
        "\n",
        "# === Fake Location Log ===\n",
        "def generate_fake_location_log():\n",
        "    # Return the location log data instead of printing\n",
        "    now = datetime.now()\n",
        "    locations = [\n",
        "        {\n",
        "            \"timestamp\": now.isoformat(),\n",
        "            \"latitude\": 12.9716,\n",
        "            \"longitude\": 77.5946,\n",
        "\n",
        "        },\n",
        "        {\n",
        "            \"timestamp\": (now + timedelta(minutes=90)).isoformat(),\n",
        "            \"latitude\": 12.9353,\n",
        "            \"longitude\": 77.6143,\n",
        "\n",
        "        }\n",
        "    ]\n",
        "    return {\n",
        "\n",
        "        \"location_log\": locations\n",
        "    }\n",
        "\n",
        "# === Guilt-Tripping Apology Generator (using pipeline from previous cells) ===\n",
        "apology_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "def generate_apology(context, tone=\"emotional\"):\n",
        "    prompt = f\"I'm deeply sorry for {context}. I feel really {tone} about it because\"\n",
        "    # Ensure prompt is within a reasonable length for the model\n",
        "    if len(prompt) > tokenizer.model_max_length:\n",
        "        prompt = prompt[:tokenizer.model_max_length]\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    # Check if pad_token_id is None and set it to eos_token_id if it is\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    # Create attention mask\n",
        "    attention_mask = inputs['input_ids'].ne(tokenizer.pad_token_id)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        apology_outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=50, # Limit apology length\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            # attention_mask=attention_mask # Removed redundant attention mask\n",
        "        )\n",
        "    apology = tokenizer.decode(apology_outputs[0], skip_special_tokens=True)\n",
        "    # Remove the prompt from the generated text\n",
        "    apology = apology[len(prompt):].strip()\n",
        "    return apology\n",
        "\n",
        "\n",
        "# === CSV Handling Functions ===\n",
        "def load_excuses_from_csv(filepath=CSV_FILE):\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        # Convert the 'Proofs' column from JSON string back to dictionary\n",
        "        if 'Proofs' in df.columns:\n",
        "            df['Proofs'] = df['Proofs'].apply(lambda x: json.loads(x) if pd.notnull(x) else {})\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        return pd.DataFrame(columns=[\"Context\", \"Tone\", \"Excuse\", \"Apology\", \"Proofs\", \"Calls\", \"Effectiveness\"])\n",
        "\n",
        "def save_excuses_to_csv(df, filepath=CSV_FILE):\n",
        "    # Convert the 'Proofs' column (dictionaries) to JSON strings before saving\n",
        "    if 'Proofs' in df.columns:\n",
        "        df['Proofs'] = df['Proofs'].apply(lambda x: json.dumps(x) if isinstance(x, dict) else x)\n",
        "    df.to_csv(filepath, index=False)\n",
        "    print(f\"\\nExcuse data saved to {filepath}\")\n",
        "\n",
        "# === Main Program ===\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== FLAN-T5 Excuse + Fake Proof Generator & CSV Saver ===\")\n",
        "\n",
        "    # Load existing data from CSV\n",
        "    all_excuses_df = load_excuses_from_csv()\n",
        "    print(f\"Loaded {len(all_excuses_df)} existing excuses from {CSV_FILE}\")\n",
        "\n",
        "    # Get user inputs for scenario and tone\n",
        "    scenario = input(\"Enter a situation (e.g., I missed the test): \")\n",
        "    # Add input for tone, as used in apology generation\n",
        "    tone = input(\"What tone should the apology have? (casual, formal, emotional - default emotional): \") or \"emotional\"\n",
        "\n",
        "\n",
        "    # Generate excuses with FLAN-T5\n",
        "    generated_excuses_text = generate_excuses(scenario, num_excuses=5)\n",
        "\n",
        "    print(f\"\\nüìù Generated {len(generated_excuses_text)} Excuses:\")\n",
        "    current_run_excuses = [] # List to hold ExcuseData objects for the current run\n",
        "\n",
        "    for i, excuse_text in enumerate(generated_excuses_text):\n",
        "        # Generate apology for each excuse (using the scenario as context)\n",
        "        apology_text = generate_apology(scenario, tone)\n",
        "\n",
        "        # Create an ExcuseData object for each generated excuse\n",
        "        excuse_data = ExcuseData(\n",
        "            context=scenario,\n",
        "            tone=tone,\n",
        "            excuse=excuse_text,\n",
        "            apology=apology_text,\n",
        "            effectiveness=random.uniform(0.5, 1.0) # Assign random effectiveness for now\n",
        "        )\n",
        "        current_run_excuses.append(excuse_data)\n",
        "        print(f\"{i+1}. {excuse_text}\")\n",
        "\n",
        "    # Rank the excuses from the current run\n",
        "    ranked_current_excuses = rank_excuses_data(current_run_excuses) # Pass the list to rank_excuses_data\n",
        "    print(\"\\nüèÖ Ranked Excuses (Current Run):\")\n",
        "    for i, excuse_data in enumerate(ranked_current_excuses):\n",
        "         print(f\"{i+1}. Effectiveness: {excuse_data.effectiveness:.2f} - {excuse_data.excuse}\")\n",
        "\n",
        "    # Ask user to select an excuse for proofs\n",
        "    selected_excuse_data = None\n",
        "    while True:\n",
        "        try:\n",
        "            selection = int(input(f\"\\nSelect an excuse number (1-{len(current_run_excuses)}) from the GENERATED list above to generate proofs for, or enter 0 to skip proofs: \"))\n",
        "            if 0 <= selection <= len(current_run_excuses):\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid selection. Please enter a number within the range.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    new_excuses_to_save_dicts = [] # List to hold dictionaries of selected excuse for saving\n",
        "    if selection > 0:\n",
        "        selected_excuse_data = current_run_excuses[selection - 1]\n",
        "        # print(f\"Type of selected_excuse_data: {type(selected_excuse_data)}\") # Added for debugging\n",
        "        print(f\"\\nGenerating proofs for selected excuse: {selected_excuse_data.excuse}\")\n",
        "\n",
        "        proofs = {}\n",
        "        # Chat log\n",
        "        if input(\"Do you want a fake chat log for this excuse? (yes/no): \").strip().lower() == 'yes':\n",
        "            chat_log_data = generate_fake_chat(selected_excuse_data.excuse)\n",
        "            proofs['chat_log'] = chat_log_data # Store the data\n",
        "            print(\"\\nüì± Chat Log:\")\n",
        "            for msg in chat_log_data:\n",
        "                print(f\"[{msg['sender']} - {msg['time']}] {msg['message']}\")\n",
        "\n",
        "        # Medical note\n",
        "        if input(\"Do you want a fake medical note? (yes/no): \").strip().lower() == 'yes':\n",
        "            medical_note_text = generate_fake_medical_note()\n",
        "            proofs['medical_note'] = medical_note_text # Store the text\n",
        "            print(\"\\nüìÑ Medical Note:\")\n",
        "            print(medical_note_text)\n",
        "\n",
        "        # Location log\n",
        "        if input(\"Do you want a fake location log? (yes/no): \").strip().lower() == 'yes':\n",
        "            location_log_data = generate_fake_location_log()\n",
        "            proofs['location_log'] = location_log_data # Store the data\n",
        "            print(\"\\nüìç Location Log (JSON):\")\n",
        "            print(json.dumps(location_log_data, indent=4))\n",
        "\n",
        "        # Update the selected ExcuseData object with generated proofs\n",
        "        selected_excuse_data.proofs = proofs\n",
        "        new_excuses_to_save_dicts.append(selected_excuse_data.to_dict()) # Add selected excuse to the list for saving\n",
        "\n",
        "    else:\n",
        "        print(\"\\nSkipping proof generation and saving for this run.\")\n",
        "\n",
        "    # Convert the selected excuse data to a DataFrame (will be empty if no excuse was selected)\n",
        "    new_excuses_df = pd.DataFrame(new_excuses_to_save_dicts)\n",
        "\n",
        "    # Append new data to the existing DataFrame\n",
        "    all_excuses_df = pd.concat([all_excuses_df, new_excuses_df], ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame back to CSV\n",
        "    save_excuses_to_csv(all_excuses_df)\n",
        "\n",
        "    # Optional: Display the full history from the CSV\n",
        "    print(\"\\n=== Full Excuse History from CSV ===\")\n",
        "    display(load_excuses_from_csv())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sOPAPN3RK-pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef75753d-370c-4397-971b-72c22dadbf5d",
        "id": "r-5_-eB2K-8L"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FLAN-T5 Excuse + Fake Proof Generator & CSV Saver ===\n",
            "Loaded 2 existing excuses from excuse_history.csv\n",
            "Enter a situation (e.g., I missed the test): didn't mail in important files \n",
            "What tone should the apology have? (casual, formal, emotional - default emotional): casual\n",
            "\n",
            "üìù Generated 5 Excuses:\n",
            "1.  i rang in files\n",
            "2.  I was ill and needed to send something\n",
            "3.  lost a new CD.\n",
            "4.  my boss says i forgot paperwork\n",
            "5.  when I was in Italy\n",
            "\n",
            "üèÖ Ranked Excuses (Current Run):\n",
            "1. Effectiveness: 0.99 -  i rang in files\n",
            "2. Effectiveness: 0.93 -  my boss says i forgot paperwork\n",
            "3. Effectiveness: 0.85 -  I was ill and needed to send something\n",
            "4. Effectiveness: 0.80 -  when I was in Italy\n",
            "5. Effectiveness: 0.72 -  lost a new CD.\n",
            "\n",
            "Select an excuse number (1-5) from the GENERATED list above to generate proofs for, or enter 0 to skip proofs: 2\n",
            "\n",
            "Generating proofs for selected excuse:  I was ill and needed to send something\n",
            "Do you want a fake chat log for this excuse? (yes/no): no\n",
            "Do you want a fake medical note? (yes/no): yes\n",
            "\n",
            "üìÑ Medical Note:\n",
            "\n",
            "------------------------------------------------------------\n",
            "                         MEDICAL CERTIFICATE\n",
            "------------------------------------------------------------\n",
            "\n",
            "To Whom It May Concern,\n",
            "\n",
            "This is to certify that John Doe has been under my care and treatment\n",
            "for the following medical reason: . The patient reported symptoms\n",
            "requiring clinical attention and was advised to take adequate rest.\n",
            "\n",
            "It is hereby recommended that John Doe be granted leave for a period\n",
            "of 7 days, starting from August 10, 2025, in order to facilitate recovery.\n",
            "\n",
            "Should you have any questions, you may contact my clinic directly.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "\n",
            "M.B.B.S., M.D.\n",
            "Reg. No: 989283\n",
            "Clinic: Health First Multispeciality, Hyderabad\n",
            "Date Issued: August 10, 2025\n",
            "------------------------------------------------------------\n",
            "\n",
            "Do you want a fake location log? (yes/no): no\n",
            "\n",
            "Excuse data saved to excuse_history.csv\n",
            "\n",
            "=== Full Excuse History from CSV ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                           Context       Tone  \\\n",
              "0         missed project deadline   emotional   \n",
              "1       I didn't come for an exam      formal   \n",
              "2  didn't mail in important files      casual   \n",
              "\n",
              "                                    Excuse  Apology  \\\n",
              "0                I'm trying to be smarter.      NaN   \n",
              "1                       I was out of town.      NaN   \n",
              "2   I was ill and needed to send something      NaN   \n",
              "\n",
              "                                              Proofs  Calls  Effectiveness  \n",
              "0                                                 {}      0       0.618033  \n",
              "1  {'location_log': {'location_log': [{'timestamp...      0       0.560939  \n",
              "2  {'medical_note': '\n",
              "---------------------------...      0       0.849021  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a110c473-02a0-4558-aac0-49c30e19a73d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context</th>\n",
              "      <th>Tone</th>\n",
              "      <th>Excuse</th>\n",
              "      <th>Apology</th>\n",
              "      <th>Proofs</th>\n",
              "      <th>Calls</th>\n",
              "      <th>Effectiveness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>missed project deadline</td>\n",
              "      <td>emotional</td>\n",
              "      <td>I'm trying to be smarter.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{}</td>\n",
              "      <td>0</td>\n",
              "      <td>0.618033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I didn't come for an exam</td>\n",
              "      <td>formal</td>\n",
              "      <td>I was out of town.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'location_log': {'location_log': [{'timestamp...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>didn't mail in important files</td>\n",
              "      <td>casual</td>\n",
              "      <td>I was ill and needed to send something</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'medical_note': '\n",
              "---------------------------...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.849021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a110c473-02a0-4558-aac0-49c30e19a73d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a110c473-02a0-4558-aac0-49c30e19a73d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a110c473-02a0-4558-aac0-49c30e19a73d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6d2125e7-5a85-4938-b1f8-b0cf1edf1dd9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d2125e7-5a85-4938-b1f8-b0cf1edf1dd9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6d2125e7-5a85-4938-b1f8-b0cf1edf1dd9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(load_excuses_from_csv())\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"missed project deadline \",\n          \"I didn't come for an exam \",\n          \"didn't mail in important files \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tone\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"emotional\",\n          \"formal\",\n          \"casual\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Excuse\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \" I'm trying to be smarter.\",\n          \" I was out of town.\",\n          \" I was ill and needed to send something\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Apology\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Proofs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Calls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Effectiveness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15253754213528767,\n        \"min\": 0.5609391110809042,\n        \"max\": 0.8490207865720991,\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, date # Import date explicitly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline # Import pipeline here\n",
        "import torch\n",
        "\n",
        "# === Constants ===\n",
        "\n",
        "CSV_FILE = 'excuse_history.csv'\n",
        "DISCLAIMER = \"Disclaimer: This chat log is fictional and generated by an AI. It should not be used for deceptive purposes.\"\n",
        "\n",
        "# === Excuse Data Structure ===\n",
        "class ExcuseData:\n",
        "    def __init__(self, context, tone, excuse, apology, proofs=None, calls=0, effectiveness=None):\n",
        "        self.context = context\n",
        "        self.tone = tone\n",
        "        self.excuse = excuse\n",
        "        self.apology = apology\n",
        "        self.proofs = proofs if proofs is not None else {}\n",
        "        self.calls = calls\n",
        "        self.effectiveness = effectiveness\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"Context\": self.context,\n",
        "            \"Tone\": self.tone,\n",
        "            \"Excuse\": self.excuse,\n",
        "            \"Apology\": self.apology,\n",
        "            \"Proofs\": json.dumps(self.proofs), # Convert proofs dictionary to JSON string\n",
        "            \"Calls\": self.calls,\n",
        "            \"Effectiveness\": self.effectiveness\n",
        "        }\n",
        "\n",
        "# === Load FLAN-T5 Model ===\n",
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# === FLAN-T5 Excuse Generator ===\n",
        "def generate_excuses(situation, num_excuses=5, max_length=50):\n",
        "    prompt = f\"Give {num_excuses} creative excuses for the following situation: {situation}\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=num_excuses,\n",
        "            temperature=0.9,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    excuses = []\n",
        "    for output in outputs:\n",
        "        decoded = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        # Prefix disclaimer\n",
        "        excuses.append(f\" {decoded}\")\n",
        "    return excuses\n",
        "\n",
        "# Excuse History & Ranking (using the ExcuseData structure)\n",
        "excuse_history_data = [] # Use this list to store ExcuseData objects for the current run\n",
        "\n",
        "def add_excuse_data(excuse_data):\n",
        "    excuse_history_data.append(excuse_data)\n",
        "\n",
        "def rank_excuses_data(excuse_list): # Modified to accept a list\n",
        "    # Rank based on the effectiveness stored in ExcuseData objects\n",
        "    return sorted(excuse_list, key=lambda x: x.effectiveness if x.effectiveness is not None else -1, reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "# === Fictional Chat Generator ===\n",
        "def generate_fake_chat(excuse):\n",
        "    # Return the chat log data instead of printing\n",
        "    return [\n",
        "        {\"sender\": \"Mom\", \"time\": \"8:42 AM\", \"message\": \"Where are you?? Your professor called üò°\"},\n",
        "        {\"sender\": \"You\", \"time\": \"8:43 AM\", \"message\": excuse},\n",
        "        {\"sender\": \"Mom\", \"time\": \"8:43 AM\", \"message\": \"Send a picture right now.\"},\n",
        "        {\"sender\": \"You\", \"time\": \"8:44 AM\", \"message\": \"Sent you one just now, look at the jam. I‚Äôll be there ASAP.\"},\n",
        "        {\"sender\": \"System\", \"time\": \"Generated Now\", \"message\": DISCLAIMER}\n",
        "    ]\n",
        "\n",
        "\n",
        "# === Medical Certificate Generator ===\n",
        "def generate_fake_medical_note(patient_name=\"John Doe\", reason=\"\"):\n",
        "    today = date.today() # Use date.today()\n",
        "    issue_date = today.strftime(\"%B %d, %Y\")\n",
        "    rest_days = random.randint(2, 7)\n",
        "\n",
        "    certificate_text = f\"\"\"\n",
        "------------------------------------------------------------\n",
        "                         MEDICAL CERTIFICATE\n",
        "------------------------------------------------------------\n",
        "\n",
        "To Whom It May Concern,\n",
        "\n",
        "This is to certify that {patient_name} has been under my care and treatment\n",
        "for the following medical reason: {reason}. The patient reported symptoms\n",
        "requiring clinical attention and was advised to take adequate rest.\n",
        "\n",
        "It is hereby recommended that {patient_name} be granted leave for a period\n",
        "of {rest_days} days, starting from {issue_date}, in order to facilitate recovery.\n",
        "\n",
        "Should you have any questions, you may contact my clinic directly.\n",
        "\n",
        "Sincerely,\n",
        "\n",
        "\n",
        "M.B.B.S., M.D.\n",
        "Reg. No: {random.randint(100000, 999999)}\n",
        "Clinic: Health First Multispeciality, Hyderabad\n",
        "Date Issued: {issue_date}\n",
        "------------------------------------------------------------\n",
        "\"\"\"\n",
        "    return certificate_text\n",
        "\n",
        "# === Fake Location Log ===\n",
        "def generate_fake_location_log():\n",
        "    # Return the location log data instead of printing\n",
        "    now = datetime.now()\n",
        "    locations = [\n",
        "        {\n",
        "            \"timestamp\": now.isoformat(),\n",
        "            \"latitude\": 12.9716,\n",
        "            \"longitude\": 77.5946,\n",
        "\n",
        "        },\n",
        "        {\n",
        "            \"timestamp\": (now + timedelta(minutes=90)).isoformat(),\n",
        "            \"latitude\": 12.9353,\n",
        "            \"longitude\": 77.6143,\n",
        "\n",
        "        }\n",
        "    ]\n",
        "    return {\n",
        "\n",
        "        \"location_log\": locations\n",
        "    }\n",
        "\n",
        "# === Guilt-Tripping Apology Generator (using pipeline from previous cells) ===\n",
        "apology_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "def generate_apology(context, tone=\"emotional\"):\n",
        "    prompt = f\"I'm deeply sorry for {context}. I feel really {tone} about it because\"\n",
        "    # Ensure prompt is within a reasonable length for the model\n",
        "    if len(prompt) > tokenizer.model_max_length:\n",
        "        prompt = prompt[:tokenizer.model_max_length]\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    # Check if pad_token_id is None and set it to eos_token_id if it is\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    # Create attention mask\n",
        "    attention_mask = inputs['input_ids'].ne(tokenizer.pad_token_id)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        apology_outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=50, # Limit apology length\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            # attention_mask=attention_mask # Removed redundant attention mask\n",
        "        )\n",
        "    apology = tokenizer.decode(apology_outputs[0], skip_special_tokens=True)\n",
        "    # Remove the prompt from the generated text\n",
        "    apology = apology[len(prompt):].strip()\n",
        "    return apology\n",
        "\n",
        "\n",
        "# === CSV Handling Functions ===\n",
        "def load_excuses_from_csv(filepath=CSV_FILE):\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        # Convert the 'Proofs' column from JSON string back to dictionary\n",
        "        if 'Proofs' in df.columns:\n",
        "            df['Proofs'] = df['Proofs'].apply(lambda x: json.loads(x) if pd.notnull(x) else {})\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        return pd.DataFrame(columns=[\"Context\", \"Tone\", \"Excuse\", \"Apology\", \"Proofs\", \"Calls\", \"Effectiveness\"])\n",
        "\n",
        "def save_excuses_to_csv(df, filepath=CSV_FILE):\n",
        "    # Convert the 'Proofs' column (dictionaries) to JSON strings before saving\n",
        "    if 'Proofs' in df.columns:\n",
        "        df['Proofs'] = df['Proofs'].apply(lambda x: json.dumps(x) if isinstance(x, dict) else x)\n",
        "    df.to_csv(filepath, index=False)\n",
        "    print(f\"\\nExcuse data saved to {filepath}\")\n",
        "\n",
        "# === Main Program ===\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== FLAN-T5 Excuse + Fake Proof Generator & CSV Saver ===\")\n",
        "\n",
        "    # Load existing data from CSV\n",
        "    all_excuses_df = load_excuses_from_csv()\n",
        "    print(f\"Loaded {len(all_excuses_df)} existing excuses from {CSV_FILE}\")\n",
        "\n",
        "    # Get user inputs for scenario and tone\n",
        "    scenario = input(\"Enter a situation (e.g., I missed the test): \")\n",
        "    # Add input for tone, as used in apology generation\n",
        "    tone = input(\"What tone should the apology have? (casual, formal, emotional - default emotional): \") or \"emotional\"\n",
        "\n",
        "\n",
        "    # Generate excuses with FLAN-T5\n",
        "    generated_excuses_text = generate_excuses(scenario, num_excuses=5)\n",
        "\n",
        "    print(f\"\\nüìù Generated {len(generated_excuses_text)} Excuses:\")\n",
        "    current_run_excuses = [] # List to hold ExcuseData objects for the current run\n",
        "\n",
        "    for i, excuse_text in enumerate(generated_excuses_text):\n",
        "        # Generate apology for each excuse (using the scenario as context)\n",
        "        apology_text = generate_apology(scenario, tone)\n",
        "\n",
        "        # Create an ExcuseData object for each generated excuse\n",
        "        excuse_data = ExcuseData(\n",
        "            context=scenario,\n",
        "            tone=tone,\n",
        "            excuse=excuse_text,\n",
        "            apology=apology_text,\n",
        "            effectiveness=random.uniform(0.5, 1.0) # Assign random effectiveness for now\n",
        "        )\n",
        "        current_run_excuses.append(excuse_data)\n",
        "        print(f\"{i+1}. {excuse_text}\")\n",
        "\n",
        "    # Rank the excuses from the current run\n",
        "    ranked_current_excuses = rank_excuses_data(current_run_excuses) # Pass the list to rank_excuses_data\n",
        "    print(\"\\nüèÖ Ranked Excuses (Current Run):\")\n",
        "    for i, excuse_data in enumerate(ranked_current_excuses):\n",
        "         print(f\"{i+1}. Effectiveness: {excuse_data.effectiveness:.2f} - {excuse_data.excuse}\")\n",
        "\n",
        "    # Ask user to select an excuse for proofs\n",
        "    selected_excuse_data = None\n",
        "    while True:\n",
        "        try:\n",
        "            selection = int(input(f\"\\nSelect an excuse number (1-{len(current_run_excuses)}) from the GENERATED list above to generate proofs for, or enter 0 to skip proofs: \"))\n",
        "            if 0 <= selection <= len(current_run_excuses):\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid selection. Please enter a number within the range.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    new_excuses_to_save_dicts = [] # List to hold dictionaries of selected excuse for saving\n",
        "    if selection > 0:\n",
        "        selected_excuse_data = current_run_excuses[selection - 1]\n",
        "        # print(f\"Type of selected_excuse_data: {type(selected_excuse_data)}\") # Added for debugging\n",
        "        print(f\"\\nGenerating proofs for selected excuse: {selected_excuse_data.excuse}\")\n",
        "\n",
        "        proofs = {}\n",
        "        # Chat log\n",
        "        if input(\"Do you want a fake chat log for this excuse? (yes/no): \").strip().lower() == 'yes':\n",
        "            chat_log_data = generate_fake_chat(selected_excuse_data.excuse)\n",
        "            proofs['chat_log'] = chat_log_data # Store the data\n",
        "            print(\"\\nüì± Chat Log:\")\n",
        "            for msg in chat_log_data:\n",
        "                print(f\"[{msg['sender']} - {msg['time']}] {msg['message']}\")\n",
        "\n",
        "        # Medical note\n",
        "        if input(\"Do you want a fake medical note? (yes/no): \").strip().lower() == 'yes':\n",
        "            medical_note_text = generate_fake_medical_note()\n",
        "            proofs['medical_note'] = medical_note_text # Store the text\n",
        "            print(\"\\nüìÑ Medical Note:\")\n",
        "            print(medical_note_text)\n",
        "\n",
        "        # Location log\n",
        "        if input(\"Do you want a fake location log? (yes/no): \").strip().lower() == 'yes':\n",
        "            location_log_data = generate_fake_location_log()\n",
        "            proofs['location_log'] = location_log_data # Store the data\n",
        "            print(\"\\nüìç Location Log (JSON):\")\n",
        "            print(json.dumps(location_log_data, indent=4))\n",
        "\n",
        "        # Update the selected ExcuseData object with generated proofs\n",
        "        selected_excuse_data.proofs = proofs\n",
        "        new_excuses_to_save_dicts.append(selected_excuse_data.to_dict()) # Add selected excuse to the list for saving\n",
        "\n",
        "    else:\n",
        "        print(\"\\nSkipping proof generation and saving for this run.\")\n",
        "\n",
        "    # Convert the selected excuse data to a DataFrame (will be empty if no excuse was selected)\n",
        "    new_excuses_df = pd.DataFrame(new_excuses_to_save_dicts)\n",
        "\n",
        "    # Append new data to the existing DataFrame\n",
        "    all_excuses_df = pd.concat([all_excuses_df, new_excuses_df], ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame back to CSV\n",
        "    save_excuses_to_csv(all_excuses_df)\n",
        "\n",
        "    # Optional: Display the full history from the CSV\n",
        "    print(\"\\n=== Full Excuse History from CSV ===\")\n",
        "    display(load_excuses_from_csv())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sViWGiANahdu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}